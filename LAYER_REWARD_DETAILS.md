# 层级奖励详细机制说明

## 🎯 层级奖励核心参数

### 基础配置
```
层级数量: 15层
每层奖励: 1% MC
解锁时间: 即时解锁
奖励来源: 推荐网络中任意层级用户的门票购买
累计最高: 15% (1% × 15层)
```

## 📊 层级奖励计算逻辑

### 奖励分配规则
```
当用户X购买门票时:
├── X的直接推荐人获得: 动态奖励25% (不是层级奖励)
├── X的推荐人的推荐人获得: 第1层奖励 1%
├── X的推荐人的推荐人的推荐人获得: 第2层奖励 1%
├── ...以此类推
└── 最多向上追溯15层，每层1%
```

### 层级计算公式
```
第N层奖励 = 门票购买金额 × 1%
条件: N ≤ 15 且 第N层推荐人存在且活跃
```

## 🔗 层级奖励详细实例

### 推荐网络结构
```
推荐链: A → B → C → D → E → F → G → H → I → J → K → L → M → N → O → P → Q

说明:
- A推荐了B
- B推荐了C  
- C推荐了D
- ...以此类推
- P推荐了Q
```

### 当Q购买1000 MC门票时的奖励分配

#### P的奖励 (Q的直接推荐人)
```
动态奖励: 1000 × 25% = 250 MC (即时解锁)
注意: P不获得层级奖励，因为P是直接推荐人
```

#### 其他人的层级奖励
```
O获得第1层奖励: 1000 × 1% = 10 MC (即时解锁)
N获得第2层奖励: 1000 × 1% = 10 MC (即时解锁)
M获得第3层奖励: 1000 × 1% = 10 MC (即时解锁)
L获得第4层奖励: 1000 × 1% = 10 MC (即时解锁)
K获得第5层奖励: 1000 × 1% = 10 MC (即时解锁)
J获得第6层奖励: 1000 × 1% = 10 MC (即时解锁)
I获得第7层奖励: 1000 × 1% = 10 MC (即时解锁)
H获得第8层奖励: 1000 × 1% = 10 MC (即时解锁)
G获得第9层奖励: 1000 × 1% = 10 MC (即时解锁)
F获得第10层奖励: 1000 × 1% = 10 MC (即时解锁)
E获得第11层奖励: 1000 × 1% = 10 MC (即时解锁)
D获得第12层奖励: 1000 × 1% = 10 MC (即时解锁)
C获得第13层奖励: 1000 × 1% = 10 MC (即时解锁)
B获得第14层奖励: 1000 × 1% = 10 MC (即时解锁)
A获得第15层奖励: 1000 × 1% = 10 MC (即时解锁)
```

#### 总奖励分配汇总
```
P (直接推荐): 250 MC (动态奖励)
O-A (15层): 15 × 10 MC = 150 MC (层级奖励)
系统总支出: 250 + 150 = 400 MC
```

## 🔍 层级奖励的关键特点

### 1. 与动态奖励的区别
```
动态奖励 (直推):
├── 奖励比例: 25%
├── 获得条件: 直接推荐关系
├── 获得人数: 1人 (直接推荐人)
└── 解锁时间: 即时

层级奖励:
├── 奖励比例: 每层1%
├── 获得条件: 间接推荐关系 (第2层开始)
├── 获得人数: 最多15人 (第1-15层)
└── 解锁时间: 即时
```

### 2. 层级计算起点
```
重要说明:
├── 第1层 = 直接推荐人的推荐人
├── 第2层 = 直接推荐人的推荐人的推荐人
├── 直接推荐人不获得层级奖励
└── 直接推荐人只获得25%动态奖励
```

### 3. 活跃用户条件
```
获得层级奖励的条件:
├── 用户必须是活跃状态 (isActive = true)
├── 用户必须有门票持有记录 (totalTickets > 0)
├── 推荐关系必须存在且有效
└── 在15层范围内
```

## 💡 层级奖励的智能合约实现

### 核心算法
```solidity
// 层级奖励分发 (从第2层开始，因为第1层是直接推荐)
address current = buyerInfo.referrer; // 买家的推荐人
uint256 layer = 1;

while (current != address(0) && layer <= 15) {
    UserInfo memory currentInfo = userInfo[current];
    
    if (currentInfo.isActive && currentInfo.totalTickets > 0) {
        uint256 layerReward = amount / 100; // 1%
        _recordDynamicReward(current, layerReward, 2, buyer, 0);
    }
    
    current = currentInfo.referrer;
    layer++;
}
```

### 奖励记录结构
```solidity
struct DynamicReward {
    uint256 amount;         // 奖励金额 (MC)
    uint256 timestamp;      // 获得时间
    uint8 sourceType;       // 来源类型 (2=层级奖励)
    address fromUser;       // 来源用户 (购买门票的用户)
    bool claimed;           // 是否已提取
    uint256 unlockTime;     // 解锁时间 (0=即时解锁)
}
```

## 📈 层级奖励的经济效应

### 网络激励效应
```
激励机制:
├── 鼓励建设深度推荐网络
├── 奖励网络中的每个活跃节点
├── 创造多层次的收益机会
└── 促进用户长期参与和维护网络
```

### 收益分布
```
对于一个完整的15层网络:
├── 每次门票购买产生15%的层级奖励
├── 分配给15个不同的网络参与者
├── 每人获得1%，公平分配
└── 即时解锁，快速激励
```

## 🎯 层级奖励实际案例

### 案例1: 短网络 (5层)
```
网络: A → B → C → D → E
E购买500 MC门票:

D获得动态奖励: 500 × 25% = 125 MC
C获得第1层奖励: 500 × 1% = 5 MC
B获得第2层奖励: 500 × 1% = 5 MC  
A获得第3层奖励: 500 × 1% = 5 MC

总层级奖励: 3 × 5 = 15 MC
```

### 案例2: 完整网络 (15层)
```
网络: A → B → C → ... → O → P
P购买1000 MC门票:

O获得动态奖励: 1000 × 25% = 250 MC
N-A获得层级奖励: 14 × (1000 × 1%) = 140 MC

总层级奖励: 140 MC
```

## 🔧 层级奖励的技术要点

### 遍历算法
```
遍历逻辑:
├── 从购买者的推荐人开始
├── 向上遍历推荐链
├── 最多遍历15层
├── 跳过非活跃用户
└── 为每个活跃用户分配1%奖励
```

### 防止无限循环
```
安全机制:
├── 最大层数限制: 15层
├── 循环计数器: iterations < 20
├── 空地址检查: current != address(0)
└── 活跃状态验证: isActive && totalTickets > 0
```

## 📋 层级奖励总结

### 核心特征
- **15层深度**: 最多向上追溯15层推荐关系
- **1%固定奖励**: 每层固定1%，不递减
- **即时解锁**: 所有层级奖励即时到账
- **活跃条件**: 只有活跃用户才能获得奖励
- **公平分配**: 每层奖励相等，鼓励网络建设

### 与其他奖励的协同
- **动态奖励**: 直接推荐人获得25%
- **层级奖励**: 间接推荐人获得1% × 15层
- **级差奖励**: 基于V等级的额外奖励
- **静态奖励**: 购买者的质押收益

这就是层级奖励的完整详细机制说明。